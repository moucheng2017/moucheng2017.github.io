<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Disease worlds models are essential for personalised medicine [Work in progress] | Moucheng Xu </title> <meta name="author" content="Moucheng Xu"> <meta name="description" content="first blog"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/capy.png?0b2cd83dee3a9232147984aa134cd1a1"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://moucheng2017.github.io/blog/2025/my-first-blog/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.css" integrity="sha256-q9ba7o845pMPFU+zcAll8rv+gC+fSovKsOoNQ6cynuQ=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github.min.css" integrity="sha256-Oppd74ucMR5a5Dq96FxjEzGF7tTw2fZ/6ksAqDCM8GY=" crossorigin="anonymous" media="screen and (prefers-color-scheme: light)"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css" integrity="sha256-nyCNAiECsdDHrr/s2OQsp5l9XeY2ZJ0rMepjCT2AkBk=" crossorigin="anonymous" media="screen and (prefers-color-scheme: dark)"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/diff2html@3.4.47/bundles/css/diff2html.min.css" integrity="sha256-IMBK4VNZp0ivwefSn51bswdsrhk0HoMTLc2GqFHFBXg=" crossorigin="anonymous"> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Moucheng</span> Xu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Disease worlds models are essential for personalised medicine [Work in progress]</h1> <p class="post-meta"> Created in July 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/comments"> <i class="fa-solid fa-hashtag fa-sm"></i> comments</a>   ·   <a href="/blog/category/perspective"> <i class="fa-solid fa-tag fa-sm"></i> perspective</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="llm-based-healthcare-ai-is-not-enough-for-personalised-medicine">LLM based healthcare AI is NOT enough for personalised medicine:</h2> <p><strong>LLM is not for personalised medicine</strong>: Every day it has become more evident that current LLMs will one day be as good as human doctors at making diagnoses. However, personalised medicine is far beyond just making a diagnosis. Unfortunately, I do not think that the current LLM systems or their future versions are designed for accurate personalised medicine. This is because they can only access partial clinical representations of patients, rather than looking holistically at the whole picture at both the individual and population levels.</p> <p><strong>World Models for personalised medicine</strong>: Recent progress in World Models has shed some light on how to realise personalised medicine for humanity using AI. World Models, such as the Google Genie series, can create physical worlds with interactive virtual environments. By analogy, we could create a Disease World Model that is fully aware of patients’ clinical representations, with an interactive environment for virtual interactions. Such a model would be able to perform virtual screening to save patients from a preventative perspective. The Disease World Model should also be able to provide virtual personal disease progression modelling for optimal treatment planning, and it could even be helpful for personalised drug development with virtual interventions.</p> <p><strong>Contents of this blog</strong>: This blog will first lay out the definitions of a Disease World Model, which provides a few future research directions and opportunities. Some early use cases with promising results on lung fibrosis will later be discussed.</p> <p><strong>Invites for collaborators</strong> This is a work in progress, so please feel free to contact me if you find a typo, a mistake, or would like to discuss or collaborate. <a href="mailto:xumoucheng28@gmail.com">xumoucheng28@gmail.com</a>.</p> <p><img src="/assets/img/blog_disease_world_models/dwm_vs_llms.png" alt="Disease World Models vs LLMs" width="100%" style="max-width: 800px; height: auto;"></p> <p><em>Figure 1: Comparison between Disease World Models and Large Language Models in AI driven healthcare. LLMs can do diagnosis but Disease World Models can do more, even personalised medicine.</em></p> <h2 id="setup-for-disease-world-model">Setup for Disease World Model</h2> <p>Before we dive into the formal definitions, we need to define a few terms:</p> <ul> <li>$X$: synthetic artifacts, as high-dimensional clinical representations (e.g., medical images, medical images + lab reports) of an individual $i \in {1, …, N}$.</li> <li>$G$: a generative system that produces a temporal sequence of artifacts ${X_i^t}_{t=0}^{t=E_i}$, where $X_i^t$ is the artifact for individual $i$ at time stamp $t$, $E_i$ is the end point (death time point) of the individual $i$.</li> <li>$Y$: real artifacts of an individual $i \in {1, …, N}$ be ${Y_i^t}_{t=S}^{t=E}$, where the real clinical representations are available during the time period between the starting point $t=S$ and the end point $t=E$.</li> <li>$M$: a diagnostic agent (e.g., human doctors, clinical LLM) that can map the clinical representations ($X$ and $Y$) to diagnosis. The accuracy of the diagnosis is measured by a metric $\mathcal{L}$.</li> <li>$I$: an identification function to recognise the identities of all sequences of the medical artifacts.</li> <li>$f_d$: a mapping function that can transform the generated artifact $X$ into another interpretable data format $d$.</li> <li>$\mathcal{I}$: a virtual intervention.</li> </ul> <hr> <h2 id="definition-1-disease-world-model">Definition 1: Disease World Model</h2> <p>A generative system $G$ is a <strong>Disease World Model</strong> if its generated artifact sequences ${X_i^t}_{t=0}^{t=E_i}$ satisfy the following properties for all individuals $i$.</p> <ol> <li> <strong>Clinical Comprehensiveness:</strong> Each generated artifact $X_i^t$ should contain the complete comprehensive clinical representation of the patient that it can be converted into any data format that is interpretable to human doctors.</li> <li> <strong>Clinical Reliability:</strong> Each generated artifact $X_i^t$ is <em>clinically reliable</em> for all $t$.</li> <li> <strong>Interventional Validity:</strong> Each generated artifact sequence under a virtual intervention is realistic and reliable.</li> <li> <strong>Individual Characterisability:</strong> Each generated artifact sequence ${X_i^t}<em>{t=0}^{t=E_i}$ is _individually characterisable</em>.</li> </ol> <hr> <h2 id="definition-11-clinical-comprehensiveness">Definition 1.1: Clinical Comprehensiveness</h2> <p>An artifact $X_i^t$ is considered <em>clinically comprehensive</em> if it satisfies two conditions:</p> <ol> <li> <strong>Comprehensive Representation:</strong> The artifact must encode the complete clinical state of the patient at a given time, rather than a single data modality. Such a comprehensive clinical representation can be seen as the <em>Clinical</em> <em>Platonic</em> <em>Representation</em> of the patient.</li> <li> <strong>Functional Convertibility:</strong> If the artifact is <em>clinically comprehensive</em>, it must contain the <em>Clinical</em> <em>Platonic</em> <em>Representation</em> of the patient. Therefore, there must exist a set of mapping functions ${f_d}$ capable of converting the artifact $X_i^t$ into any clinically relevant target format $d$ (e.g., medical image, text report, lab reports) that is interpretable by human doctors. Each function performs the transformation $X^t_{i^d} = f_d(X_i^t)$. This ensures that a lot of the existing clinical workflows in the physical world can still be applied on the generated artifacts. It also ensures that the generated artifacts can be directly evaluated for their correctness.</li> </ol> <hr> <h2 id="definition-12-clinical-reliability">Definition 1.2: Clinical Reliability</h2> <p>An artifact $X_i^t$ is <strong>clinically reliable</strong> if, for a given diagnostic agent $M$ and accuracy metric $\mathcal{L}$, the following conditions hold:</p> <ol> <li> <p><strong>Diagnostic Verifiability:</strong> The accuracy of a diagnosis derived from the synthetic artifact should be larger than a threshold $\alpha$:</p> <p>$L(M(X_i^t)) \ge \alpha, \quad t \in {S, \dots, E}$</p> <p>In the strictest scenario, the diagnostic accuracy from the synthetic artifact should be at least as good as the real artifacts, more formally, we can define $\alpha \ge L(M(Y_i^t)), \quad t \in {S, \dots, E}$. In less strict scenarios, a threshold $\alpha$ needs to be determined to be clinically accetable. This condition ensures the diagnostic utility of the synthetic artifacts is useable and verifiable.</p> </li> <li> <p><strong>Temporal Consistency:</strong> The diagnostic accuracy is a non-decreasing function of time. For any two time points $t_1$ and $t_2$ such that $t_1 &lt; t_2$, we have:</p> <p>$L(M(X_i^{t_1})) \le L(M(X_i^{t_2})), \quad t_1 &lt; t_2$</p> <p>Commonly, existing ML models struggle with predicting a time point that is too far away from now on. This condition ensures the diagnostic utility of the synthetic artifacts is reliable, even for future unseen timepoints.</p> </li> </ol> <hr> <h2 id="definition-13-interventional-validity">Definition 1.3: Interventional Validity</h2> <p>Let $\mathcal{I}$ be a virtual interaction (e.g., administering a drug, performing surgery, changing of the time) applied at time $t_{\mathcal{I}}$. The generative system $G$ has <em>interventional validity</em> if it can generate a reliable counterfactual sequence that satisfies the following conditions:</p> <ol> <li> <strong>Counterfactual Plausibility</strong>: The generated post-intervention trajectory ${ X_i^t \mid \mathcal{I} }$ is clinically plausible and consistent with established medical knowledge regarding the effects of intervention $\mathcal{I}$. This ensures that the interactions injected from the physical world have meaningful consequences to the artifacts. One of the simplest interactions can be the change of time, to see the artifacts at different arbitrary time points.</li> <li> <strong>Post-Intervention Reliability</strong>: Each artifact $X_i^t \mid \mathcal{I}$ generated after the intervention (i.e., for $t \geq t_{\mathcal{I}}$) remains <em>clinically reliable</em> as defined in Definition 1.2. This ensures that the effectiveness of the virtual clinical interactions can be trusted and directly assessed for drug developments and personal treatment planning.</li> </ol> <hr> <h2 id="definition-14-individual-characterisability">Definition 1.4: Individual Characterisability</h2> <p>A sequence of artifacts ${X_i^t}<em>{t=0}^{t=E_i}$ is _individually</em> <em>characterisable</em> to ensure that the sequence contains a unique signature of the individual’s disease progression, if it satisfies the following conditions:</p> <ol> <li> <p><strong>Identifiability:</strong> There exists an identification function $I$ that can identify the individual $i$ from their generated sequence with a high probability $\beta$ close to 1.</p> <p>$\mathbb{P}(I({X_i^t}_{t=0}^{t=E_i}) = i) \ge \beta$</p> <p>An example of such an ientification function $I$ is an unsupervised contrastive clustering algorithm at a very granular level.</p> </li> <li> <p><strong>Endpoint Fidelity:</strong> The generated trajectory for an individual must terminate at a clinically plausible endpoint. When the ground-truth time of death, $E_i^*$, is available for comparison, the sequence’s simulated time of death, $E_i$, must align with it within a predefined, clinically acceptable margin $\delta_E$.</p> <p>$E_i - E_i^* \le \delta_E$</p> <p>This ensures the model accurately captures the overall duration and prognostic outcome of the individual’s specific disease progression pattern.</p> </li> </ol> <hr> <h2 id="how-to-train-such-a-disease-world-model">How to train such a Disease World Model</h2> <p>To be updated</p> <p><img src="/assets/img/blog_disease_world_models/dwm_training.png" alt="Training" width="100%" style="max-width: 800px; height: auto;"></p> <p><em>Figure 2: A proposal for the training strategy of a disease world model.</em></p> <h2 id="an-early-attempted-use-case-that-is-applied-to-lung-fibrosis-disease-progression-modelling">An early attempted use case that is applied to lung fibrosis disease progression modelling</h2> <p><strong>4D-VQGAN</strong>: We built an AI model called 4D VQ-GAN for disease progression modelling of the lung fibrosis disease that satisfies the clinical reliability condition of a disease world model. In the context of the disease progression, we can adapt temporal medical imaging as the environments, on the analogy as using the videos as environments in physical world models. As a proof of concept, our early attempt only focus on only one interactive action with the virtual progression trajectories, which is the time. The technical details of this preliminary study can be found in the published conference paper: <a href="https://openreview.net/forum?id=tU3IpPQCEc&amp;noteId=tU3IpPQCEc" rel="external nofollow noopener" target="_blank">4D VQGAN</a>. Given two 3D CT scans of an Idiopathic Pulmonary Fibrosis patient at irregular time points, 4D VQ-GAN can generate synthetic 3D images at any desired time point, effectively modelling a virtual continuous disease progression trajectory for each individual. More importantly, we found that biomarkers derived from the generated CT volumes exhibit a strong clinical correlation with survival outcome, partially satisfying the clinical reliability condition as defined above, thereby highlighting the potential of 4D VQ-GAN for personalized treatment planning and more personalised medicine tasks.</p> <p><img src="/assets/img/publication_preview/side_by_side_1200_border.gif" alt="synthetic scans gif"></p> <p><em>Figure 3: An example of generated synthetic imaging medical artifacts sequence compared against the real sequence. Note that the real scans only contain scans at time point year 0, year2, year 3.5, but the generated scans have more time points at year 0, year 1.5, year 2, year 3.5, year 5.5.</em></p> <p><img src="/assets/img/publication_preview/4dvqgan_example.png" alt="synthetic scans detailed" width="100%" style="max-width: 800px; height: auto;"></p> <p><em>Figure 4: Highlighted key visual features of lung fibrosis in generated imaging artifacts. A zoomed region of the left lower lobe (yellow box) in the real and generated CT scans show comparable amounts of architectural distortion, patterned ground glass opacification and reticulation, all hallmarks of lung fibrosis. The availability of our scans are not uniform across time and across patients, the model is trained on scans at irregular time points</em></p> <p><strong>Verifiable Clinical Reliability</strong>: We explore our model’s clinical utility using a survival analysis based approach to mimic the clinical workflows. Radiologists track prognostic imaging biomarkers in IPF over time to assess disease progression. Though we lack comprehensive visual scores for all cases, we propose a method that mirrors clinical workflows, including selecting key prognostic biomarkers, analyzing their longitudinal changes, and comparing their prognostic value in synthesized vs. real scans. These extracted imaging biomarkers, along with the covariates, are input into the Cox model to assess their prognostic value in the test dataset. This analysis evaluates the consistency of biomarker trajectories between real and synthetic scans, and explores the potential utility of synthetic scans in tracking changes over time. As shown in the below results, it is very interesting to see that the generated CT images can yield survival outcomes that are sometimes even more accurate than those derived from the real images. However, these results may be overestimated due to the limited sample size.</p> <p><img src="/assets/img/blog_disease_world_models/survival_outcomes.png" alt="survival outcome" width="100%" style="max-width: 800px; height: auto;"></p> <p><em>Figure 5: For the cross-sectional imaging biomarker, the C-index using the generated third scans is 0.943. In comparison, using biomarkers derived from real CT scans for survival prediction yields a slightly lower C-index of 0.914. Next, we compute the longitudinal biomarker by evaluating the change in these top five significant biomarkers over the course of one year, both for real and generated CT scans. By inputting these longitudinal biomarkers along with covariates into the Cox model, we obtain C-indices of 1.0 for both real and generated CT scans.</em></p> <p>Although the existing 4D VQ-GAN is a step towards the disease world model with promising results, further study is still required to verify if the 4D VQ-GAN also satisfies the clinical reliability condition due to the lack of time and computational resources.</p> <h2 id="references">References:</h2> <ol> <li> <a href="https://icml.cc/virtual/2024/oral/35508" rel="external nofollow noopener" target="_blank">Genie: Generative Interactive Environments</a> ICML 2024</li> <li> <a href="https://proceedings.mlr.press/v235/hughes24a.html" rel="external nofollow noopener" target="_blank">Open-Endedness is Essential for Artificial Superhuman Intelligence</a> ICML 2024</li> <li> <a href="https://openreview.net/forum?id=tU3IpPQCEc&amp;noteId=tU3IpPQCEc" rel="external nofollow noopener" target="_blank">4D-VQ-GAN: A World Model for Synthesizing Medical Scans at Any Time Point for Personalized Disease Progression Modeling of Idiopathic Pulmonary Fibrosis</a> MIDL 2025</li> <li> <a href="https://phillipi.github.io/prh/" rel="external nofollow noopener" target="_blank">The Platonic Representation Hypothesis</a> ICML 2024</li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Moucheng Xu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script>let mermaidTheme=determineComputedTheme();document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&(document.querySelectorAll("pre>code.language-mermaid").forEach(e=>{const t=e.textContent,d=e.parentElement;d.classList.add("unloaded");let a=document.createElement("pre");a.classList.add("mermaid");const n=document.createTextNode(t);a.appendChild(n),d.after(a)}),mermaid.initialize({theme:mermaidTheme}),"undefined"!=typeof d3&&window.addEventListener("load",function(){d3.selectAll(".mermaid svg").each(function(){var e=d3.select(this);e.html("<g>"+e.html()+"</g>");var t=e.select("g"),d=d3.zoom().on("zoom",function(e){t.attr("transform",e.transform)});e.call(d)})}))});</script> <script src="https://cdn.jsdelivr.net/npm/diff2html@3.4.47/bundles/js/diff2html-ui.min.js" integrity="sha256-eU2TVHX633T1o/bTQp6iIJByYJEtZThhF9bKz/DcbbY=" crossorigin="anonymous"></script> <script>let diff2HtmlTheme=determineComputedTheme();document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-diff2html").forEach(e=>{const t=e.textContent,d=e.parentElement;d.classList.add("unloaded");let l=document.createElement("div");l.classList.add("diff2html"),d.after(l),new Diff2HtmlUI(l,t,{colorScheme:diff2HtmlTheme,drawFileList:!0,highlight:!0,matching:"lines"}).draw()})});</script> <script src="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.js" integrity="sha256-MgH13bFTTNqsnuEoqNPBLDaqxjGH+lCpqrukmXc8Ppg=" crossorigin="anonymous"></script> <script>document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-geojson").forEach(e=>{const t=e.textContent,a=e.parentElement;a.classList.add("unloaded");let o=document.createElement("div");o.classList.add("map"),a.after(o);var n=L.map(o);L.tileLayer("https://tile.openstreetmap.org/{z}/{x}/{y}.png",{maxZoom:19,attribution:'&copy; <a href="http://www.openstreetmap.org/copyright">OpenStreetMap</a>'}).addTo(n);let d=L.geoJSON(JSON.parse(t)).addTo(n);n.fitBounds(d.getBounds())})});</script> <script defer src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js" integrity="sha256-0q+JdOlScWOHcunpUk21uab1jW7C1deBQARHtKMcaB4=" crossorigin="anonymous"></script> <script>$(document).ready(function(){var t=null,a=null,e=null,n="";$(".language-chartjs").each(function(){a=$(this),t=$("<canvas></canvas>"),n=a.text(),a.text("").append(t),(e=t.get(0).getContext("2d"))&&n&&new Chart(e,JSON.parse(n))&&a.attr("data-processed",!0)})});</script> <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/dist/echarts.min.js" integrity="sha256-QvgynZibb2U53SsVu98NggJXYqwRL7tg3FeyfXvPOUY=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/theme/dark-fresh-cut.js" integrity="sha256-sm6Ui9w41++ZCWmIWDLC18a6ki72FQpWDiYTDxEPXwU=" crossorigin="anonymous"></script> <script>let echartsTheme=determineComputedTheme();document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-echarts").forEach(e=>{const t=e.textContent,a=e.parentElement;a.classList.add("unloaded");let r=document.createElement("div");if(r.classList.add("echarts"),a.after(r),"dark"===echartsTheme)var n=echarts.init(r,"dark-fresh-cut");else n=echarts.init(r);n.setOption(JSON.parse(t)),window.addEventListener("resize",function(){n.resize()})})});</script> <script defer src="https://cdn.jsdelivr.net/npm/vega@5.27.0/build/vega.min.js" integrity="sha256-Yot/cfgMMMpFwkp/5azR20Tfkt24PFqQ6IQS+80HIZs=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega-lite@5.16.3/build/vega-lite.min.js" integrity="sha256-TvBvIS5jUN4BSy009usRjNzjI1qRrHPYv7xVLJyjUyw=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega-embed@6.24.0/build/vega-embed.min.js" integrity="sha256-FPCJ9JYCC9AZSpvC/t/wHBX7ybueZhIqOMjpWqfl3DU=" crossorigin="anonymous"></script> <script>let vegaTheme=determineComputedTheme();document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-vega_lite").forEach(e=>{const t=e.textContent,a=e.parentElement;a.classList.add("unloaded");let d=document.createElement("div");d.classList.add("vega-lite"),a.after(d),"dark"===vegaTheme?vegaEmbed(d,JSON.parse(t),{theme:"dark"}):vegaEmbed(d,JSON.parse(t))})});</script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script src="/assets/js/typograms.js?63f3caa50c7a9624f953b3aec207afa6"></script> <script>document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-typograms").forEach(e=>{const t=e.textContent,n=e.parentElement.parentElement;let a=document.createElement("pre");a.classList.add("typogram");const d=create("\n"+t,.3,!1);a.appendChild(d),n.appendChild(a),n.removeChild(e.parentElement)})});</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams"}};</script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>